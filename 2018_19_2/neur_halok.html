<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:300,400,500" rel="stylesheet">
    <title>Neurális hálók</title>
    <style>
        :root{
            --dark-blue: #4c7783;
            --white: #f2f0f6;
            --pink: #e67b82;
            --dark-pink: #c26168;
            --blue: #65cbc3;
            --red: rgb(190, 50, 50);
            --shadow: 2px 2px 10px -3px rgba(0, 0, 0, 0.5);
        }
        body{
            background-color: var(--white);
            margin: 0!important;
            padding: 0;
        }
        *, body{
            font-family: 'Montserrat', sans-serif;
            font-weight: inherit;
        }
        h2{
            color: var(--dark-pink);
            position: relative;
            padding-bottom: 0.6rem;
            font-size: 1.6rem;
        }

        h2::after{
            position: absolute;
            bottom: 0;
            margin-top: 10px;
            content: ' ';
            background-color: var(--dark-pink);
            width: 100%;
            height: 1px;
            left: 0;
        }

        .header{
            padding: 5vh 5vw;
            background-color: var(--dark-blue);
            color: var(--white);
        }

        main {
            padding: 10vh 10vw;
            font-weight: 400;
            color: #333;
            font-size: 0.9em;
        }

        ul{
            margin-bottom: 0.3rem;
        }
        ul > li > ul >li > ul{
            color: #555;
        }

        a, a:hover{
            color: var(--dark-blue);
            text-decoration: none;
            transition: all ease-in-out .12s;
        }
        a:hover{
            color: var(--blue);
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Neurális hálók</h1>
    </div>
    <main>
        <h2>1. Előadás</h2>
        <ul>
            <li>Tárgykövetelmények</li>
            <ul>
                <li>4 kredit</li>
                <li>1 nagyházi</li>
                <ul>
                    <li>1 fős csapatok</li>
                    <li>2 fős csapatok (dupla munka)</li>
                </ul>
                <li>Szóbeli vizsga</li>
                <li>Jegyzet</li>
                <ul>
                    <li><a href="http://www.mit.bme.hu/books">Horváth Gábor: Neurális hálózatok</a></li>
                    <li><a href="http://www.deeplearningbook.org">Deep learning</a> </li>
                    <li>Machine learning and pattern recognition</li>
                </ul>
                <li>Előkövetelmények</li>
                <ul>
                    <li>Komoly matematikai háttér kell</li>
                    <li>Lineáris algebrai ismeretek</li>
                </ul>
            </ul>
            <li>Bevezetés</li>
            <ul>
                <li>Nagyon felfutó kutatási terület</li>
                <li>Biológiai inspiráció</li>
                <li>Felhasználási terúlet</li>
                <ul>
                    <li>Nehezen (egyáltalán nem) algoritmizálható problémák</li>
                    <ul>
                        <li>Mintafelismerés, elemzés</li>
                        <li>Képelemzés</li>
                        <li>Előrejelzés (időjárás / árfolyam)</li>
                    </ul>
                    <li>NP teljes, NP nehéz problémahalmazok</li>
                    <ul>
                        <li>Közelítő eljárás</li>
                        <li>Nem tud optimális eredményt / bizonyítást</li>
                    </ul>
                    <li>Nem használjuk biztonságkritikus rendszerekben</li>
                    <ul>
                        <li>Túl kiszámíthatatlan</li>
                        <li>Adaptivitás a robosztusság kárára</li>
                    </ul>
                    <li>"Nem lineáris rendszerek identifikációja"</li>
                </ul>
                <li>Adaptív rendszerek konstruálása</li>
                <ul>
                    <li>Nincs előre determinált viselkedés</li>
                    <li>Bemeneti mintákból "tanulva" approximál kimenetet</li>
                    <li>Leképezések csinál korábbi futásait felhasználva</li>
                    <li>Nem csak a korábbi mintákat képes felismerni</li>
                    <li>Bármilyen új mintára megpróbál jó közelítést</li>
                    <li>A minta változását képes követni</li>
                </ul>
                <li>Párhuzamosság</li>
                <ul>
                    <li>Pl. multiprocesszoros rendszerek</li>
                </ul>
                <li>Robosztusság</li>
                <ul>
                    <li>A kimenet nem függ túlságosan 1 "neurontól"</li>
                    <li>Redundáns adatokat is tárolunk</li>
                    <li>A redundancia robosztusságot eredményez</li>
                    <li>De szükségünk van nagy adaptivitásra</li>
                </ul>
            </ul>
            <li>Történeti háttér</li>
            <ul>
                <li>Nem követelmény, érdekesség</li>
                <li>Egy biológus alkotta meg a neuron modellt</li>
                <li>1949: neuron adaptációs modell</li>
                <ul>
                    <li>Közelítés arra, hogy egy neuron (vagy az egész háló) hogyan tanul</li>
                </ul>
                <li>Mesterségesen tantható neuron</li>
                <li>1960: adaptív lineáris neuron</li>
                <li>1969: MIT &rarr; "A neurális háló soha nem lesz tanítható"</li>
                <li>Sokáig senki nem akart ezzel foglalkozni</li>
                <li>1982: Numerikus optimalizációs problémákra nagyságrendileg jobb megoldás neurhálókkal</li>
                <li>Újabb tanítási eljárás (hibavisszajelzéses)</li>
                <li>1989: "A neurális háló mindenre jó"</li>
                <li>199X: Bebizonyosodtak a neurhálók hátrányai</li>
                <li>Statisztikus tanulás elmélet</li>
                <ul>
                    <li>A tanulási folyamat matematikai modellje</li>
                    <li>Általánosítóképesség valódi jellemzése</li>
                </ul>
                <li>Supportive vector machine (SVM)</li>
                <ul>
                    <li>A neurális háló kutatás sokáig State of the art-ja</li>
                </ul>
                <li>2012: Újabb felfutás</li>
                <ul>
                    <li>Konvolúciós neurális hálók</li>
                    <li>Mély neurális hálók</li>
                </ul>
                <li>2019: Valószínűleg lesz még lecsengése, de felfutása</li>
            </ul>
            <li>Roseblatt percepron</li>
            <ul>
                <li>Lineáris szeparációs problémák mutatása</li>
                <li>Két problémahalmazhoz meg tudja állapítani egy probléma melyikbe tartozik</li>
                <li>A 2 problémahalmaz egy hipersíkkal elválasztható (ha létezik)</li>
                <li>Súlyvektorok és egy eltolásparaméter (b) segítségét használja</li>
                <li>"d" az elvárt kimenet</li>
                <li>d = 1, ha x &isin; X, egyébként d = -1</li>
                <li>Leképezés</li>
                <ul>
                    <li>y(<u>x</u>) = sgn( <u>w<sup>T</sup>(k)</u> + <u>x <sub>1</sub></u>(k) + b )</li>
                    <li> <u>w</u> = [b, w<sub>1</sub>, w<sub>2</sub>, w<sub>3</sub>, ... ] </li>
                </ul>
                <li>Rosenblatt tanulási szabály</li>
                <ul>
                    <li><u>w(k + 1)</u> = <u>w(k)</u> + &mu; &epsilon;(k) <u>x(k)</u></li>
                    <li>&epsilon;(k) hiba faktor</li>
                    <li>&sigma;(k) = d( <u>x(k)</u> ) - y( <u>x(k)</u> )</li>
                    <li>&mu; pozitív valós (bátorsági faktor)</li>
                </ul>
                <ol>
                    <li>&epsilon;(k) = 0</li>
                    <ul>
                        <li>Nem volt hiba</li>
                        <li>Ekkor <u>w(k + 1)</u> = <u>w(k)</u></li>
                    </ul>
                    <li>&epsilon;(k) = 2</li>
                    <ul>
                        <li>d = 1, y = -1</li>
                        <ul>
                            <li><u>w<sup>T</sup></u>(k+1) + <u>x <sub>1</sub></u>(k) = 
                                <u>w</u>(k)<u>x</u>(k) + &mu; (-2)) ||<u>x</u>(k)||
                        </ul>
                    </ul>
                    <li>&epsilon;(k) = 2</li>
                    <ul>
                        <li>d = -1, y = 1</li>
                        <ul>
                            <li><u>w<sup>T</sup></u>(k+1) + <u>x <sub>1</sub></u>(k) = 
                                <u>w</u>(k)<u>x</u>(k) + &mu; (2)) ||<u>x</u>(k)||
                        </ul>
                    </ul>
                </ol>
                <li>Ha &mu; = 1/2, akkor</li>
                <ul>
                    <li>Ha a gép nem hibázott, akkor nem változik a súlyvektor</li>
                    <li>Ha a gép hibázott, akkor a súlyvektort eltoljuk bemeneti x normalizáltjával</li>
                </ul>
                <li>Tétel: véges sok iterációból betanítható</li>
                <ul>
                    <li><u>w(k + 1)</u> = <u>w(k)</u> + &mu; &epsilon;(k) <u>x(k)</u></li>
                    <ol>
                        <li>w(0) = 0</li>
                        <ul>
                            <li>w(k + 1) = &mu; &sum;(&epsilon;(i) * x(i))</li>
                        </ul>
                        <li>X <sup>(-1)'</sup> = { -x: x &isin; X <sup>(-1)</sup> }</li>
                        <ul>
                            <li>w(k + 1) = &mu; &sum;(&epsilon;(i) * x(i)) = &mu; 2 &sum;x(i)</li>
                            <li>Vegyük csak azokat az iterációkat ahol volt módosulás (k > k')</li>
                            <li>w(k+1)w* = &mu; 2 &sum;x(i) w* &geq; &mu; k' 2 b</li>
                            <ul>
                                <li>w* <sup>T</sup> x >= b</li>
                            </ul>
                            <li>||w(k+1)|| ||w*|| = (w(k+1)w*) <sup>2</sup> &geq; 2k'&mu;<sup>2</sup>b<sup>2</sup></li>
                        </ul>
                    </ol>
                </ul>
                <li>Alsó becslé</li>
                <ul>
                    <li><u>w(k + 1)</u> = <u>w(k)</u> + &mu; &epsilon;(k) <u>x(k)</u></li>
                    <li>Vegyük mind2 oldal 2-es normáját</li>
                    <li>||w(k+1)|| = ||w(k)|| + 2 &mu; &epsilon;(k) w(k) x(k) + &mu;<sup>2</sup>&epsilon;<sup>2</sup>||x(k)||</li>
                    <li>Vegyük csak azokat az iterációkat ahol volt módosulás</li>
                    <li>&epsilon; = 2, w(k) x(k) negatív</li>
                    <li>||w(k+1)|| &leq; ||w(k)|| + &mu;<sup>2</sup>4||x(k)||</li>
                    <li>||w(k+1)|| &leq; &mu;<sup>2</sup>4*b<sup>2</sup>k'</li>
                </ul>
                <li>Az alsó és a felső becslés megegyezik &rarr; az algoritmus leáll véges lépésből</li>
            </ul>
        </ul>
    </main>
</body>
</html>
